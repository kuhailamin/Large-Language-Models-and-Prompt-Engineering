{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cajlrqwlgROv"
      },
      "outputs": [],
      "source": [
        "1.\timport csv\n",
        "2.\tfrom langchain_core.documents import Document\n",
        "3.\tfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "4.\tfrom langchain_community.vectorstores import FAISS\n",
        "5.\tfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "6.\tfrom langchain.chains import RetrievalQA\n",
        "7.\n",
        "8.\t# Step 1: Load CSV file\n",
        "9.\tcsv_path = \"customer_support_tickets.csv\"\n",
        "10.\tdocuments = []\n",
        "11.\n",
        "12.\twith open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
        "13.\t   reader = csv.DictReader(csvfile)\n",
        "14.\t   for index, row in enumerate(reader):\n",
        "15.\t       # Build the content from subject, description, and resolution\n",
        "16.\t       content = f\"\"\"Customer Issue: {row['Ticket Subject']}\\nDescription: {row['Ticket Description']}\\nSupport Response: {row['Resolution']}\"\"\"\n",
        "17.\t       documents.append(Document(page_content=content, metadata={\"source\": f\"ticket_{index}\"}))\n",
        "18.\n",
        "19.\t# Step 2: Chunking\n",
        "20.\tsplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "21.\tchunks = splitter.split_documents(documents)\n",
        "22.\n",
        "23.\t# Step 3: Generate Embeddings\n",
        "24.\tembeddings = OpenAIEmbeddings(openai_api_key=\"API-KEY\")\n",
        "25.\tvectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "26.\tretriever = vectorstore.as_retriever()\n",
        "27.\n",
        "28.\t# Step 4: Use an LLM model\n",
        "29.\tllm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.2, openai_api_key=\"API-KEY\")\n",
        "30.\n",
        "31.\t# Step 5: Use a RAG chain\n",
        "32.\trag_chain = RetrievalQA.from_chain_type(\n",
        "33.\t   llm=llm,\n",
        "34.\t   chain_type=\"stuff\",\n",
        "35.\t   retriever=retriever,\n",
        "36.\t   return_source_documents=True\n",
        "37.\t)\n",
        "38.\n",
        "39.\t# Step 6: Ask a query\n",
        "40.\tquery = \"What should I do if my software crashes?\"\n",
        "41.\tresult = rag_chain.invoke(query)\n",
        "42.\n",
        "43.\tprint(\"\\nAnswer:\\n\", result['result'])\n",
        "44.\tprint(\"\\nSources:\")\n",
        "45.\tfor doc in result['source_documents']:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1.\timport csv\n",
        "2.\tfrom langchain.chains import LLMChain\n",
        "3.\tfrom langchain.prompts import PromptTemplate\n",
        "4.\tfrom langchain_openai import ChatOpenAI\n",
        "5.\n",
        "6.\t# Step 1: load the dataset (reviews_dataset.csv)\n",
        "7.\tcsv_path = \"reviews_dataset.csv\"\n",
        "8.\tcomments = []\n",
        "9.\n",
        "10.\twith open(csv_path, newline='', encoding='cp1252') as csvfile:\n",
        "11.\t   reader = csv.DictReader(csvfile)\n",
        "12.\t   for row in reader:\n",
        "13.\t       if row.get(\"Comments\"):\n",
        "14.\t           comments.append(row[\"Comments\"])\n",
        "15.\n",
        "16.\t# Step 2: set up the LLM\n",
        "17.\tllm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.2, openai_api_key=\"api key\")\n",
        "18.\n",
        "19.\t# Step 3: define a prompt that extracts polarity\n",
        "20.\tpolarity_prompt = PromptTemplate(\n",
        "21.\t   input_variables=[\"review\"],\n",
        "22.\t   template=\"\"\"\n",
        "23.\t   Analyze the sentiment polarity (Positive, Neutral, or Negative) of the following customer review:\n",
        "24.\t   Review: {review}\n",
        "25.\t   \"\"\"\n",
        "26.\t)\n",
        "27.\n",
        "28.\t# Step 3: define a prompt that extracts aspect-based sentiment (product, service, delivery)\n",
        "29.\taspect_prompt = PromptTemplate(\n",
        "30.\t   input_variables=[\"review\"],\n",
        "31.\t   template=\"\"\"\n",
        "32.\t   Analyze this customer review and extract sentiment for the following aspects: Product, Service, and Delivery.\n",
        "33.\t   Return the aspect sentiments in this format:\n",
        "34.\t   Product: [Positive/Neutral/Negative]\n",
        "35.\t   Service: [Positive/Neutral/Negative]\n",
        "36.\t   Delivery: [Positive/Neutral/Negative]\n",
        "37.\n",
        "38.\t   Review: {review}\n",
        "39.\t   \"\"\"\n",
        "40.\t)\n",
        "41.\n",
        "42.\t# Step 4: build the prompt chains\n",
        "43.\tpolarity_chain = polarity_prompt | llm\n",
        "44.\taspect_chain = aspect_prompt | llm\n",
        "45.\n",
        "46.\t# Step 5: run the analysis, and substitute the review argument\n",
        "47.\tfor index, comment in enumerate(comments, 1):\n",
        "48.\t   print(f\"\\n--- Review #{index} ---\")\n",
        "49.\t   print(\"Original Comment:\", comment)\n",
        "50.\n",
        "51.\t   polarity = polarity_chain.invoke({\"review\": comment}).content.strip()\n",
        "52.\t   aspects = aspect_chain.invoke({\"review\": comment}).content.strip()\n",
        "53.\n",
        "54.\t   print(\"Polarity:\", polarity)\n",
        "55.\t   print(\"Aspect-Based Sentiment:\\n\", aspects)\n"
      ],
      "metadata": {
        "id": "dEMc1CcRgVAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1.\tfrom langchain_core.documents import Document\n",
        "2.\tfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "3.\tfrom langchain_community.vectorstores import FAISS\n",
        "4.\tfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "5.\tfrom langchain.chains import RetrievalQA\n",
        "6.\n",
        "7.\t# Step 1: Load the policy document\n",
        "8.\twith open(\"policy.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "9.\t   policy_text = f.read()\n",
        "10.\n",
        "11.\tdocuments = [Document(page_content=policy_text)]\n",
        "12.\n",
        "13.\t# Step 2: Chunk the policy document and create embeddings.\n",
        "14.\tsplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "15.\tchunks = splitter.split_documents(documents)\n",
        "16.\n",
        "17.\t# Step 3: create the vector index\n",
        "18.\tembeddings = OpenAIEmbeddings(openai_api_key=\"api-key\")\n",
        "19.\tvectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "20.\tretriever = vectorstore.as_retriever()\n",
        "21.\n",
        "22.\t# Step 4: set up the LLM\n",
        "23.\tllm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.3, openai_api_key=\"api-key\")\n",
        "24.\n",
        "25.\t# Step 5: Set up the RAG system\n",
        "26.\trag_chain = RetrievalQA.from_chain_type(\n",
        "27.\t   llm=llm,\n",
        "28.\t   chain_type=\"stuff\",  # simple concatenation of retrieved policy text\n",
        "29.\t   retriever=retriever,\n",
        "30.\t   return_source_documents=True\n",
        "31.\t)\n",
        "32.\n",
        "33.\t# Step 6: Show an example of handling a complaint\n",
        "34.\tcomplaint = \"My sushi arrived cold and 45 minutes late. Can I get a refund?\"\n",
        "35.\n",
        "36.\tresult = rag_chain.invoke(complaint)\n",
        "37.\n",
        "38.\t# Step 7: Show resolution and evidence\n",
        "39.\tprint(\"\\nResolution:\\n\", result[\"result\"])\n",
        "40.\tprint(\"\\nPolicy Evidence Used:\")\n",
        "41.\tfor doc in result['source_documents']:\n",
        "42.\t  print(f\"- {doc.page_content[:150]}...\")"
      ],
      "metadata": {
        "id": "MhjVEDGhgZpx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}